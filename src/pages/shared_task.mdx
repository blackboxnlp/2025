# Shared Task

⚠️ **Interested in participating?** Join our [Discord server](https://discord.gg/6QhDHCJ9) to stay updated and share your ideas with other participants!

## Call for Submissions

The field of mechanistic interpretability (MI) is rapidly advancing, yet comparing the efficacy of new methods remains challenging. To foster rigorous evaluation and drive progress, BlackboxNLP 2025 will host a shared task for benchmarking new techniques for localizing circuits and causal latent variables in language models (LM).
<br/>
The shared task will leverage the recently proposed [Mechanistic Interpretability Benchmark (MIB)](https://mib-bench.github.io/) by [Mueller* & Geiger* et al. (2025)](https://arxiv.org/abs/2504.13151v1). Participants are invited to submit approaches that tackle tasks in two distinct tracks: **Circuit Localization**, i.e. identifying subsets of the LM computation graph that performs a specific task, and **Causal Variable Localization**, i.e. aligning model representations with specific known causal variables.
<br/>
![MIB Benchmark Logo](https://mib-bench.github.io/img/mib_logo.png)
<br/>
The goal is to benchmark the ability of existing MI methods and identify promising directions to precisely and concisely recover relevant causal pathways or specific causal variables in neural language models. This Call for Papers provides the rules, timeline, and participation details for the shared task. We invite researchers working on attribution, circuit discovery, feature alignment, sparse coding, and related interpretability techniques to participate.
<br/>
Refer to the original [MIB Benchmark page](https://mib-bench.github.io/) and the [related paper](https://arxiv.org/abs/2504.13151v1) for more details on the MIB benchmark and its evaluation metrics.

## Important dates

- **May 14th** - Release of the Call for Submissions, including links to [data](https://huggingface.co/collections/mib-bench/mib-datasets-67f55273612ec3067a42a56b)  and [evaluation details](https://github.com/aaronmueller/MIB).

- **August 1st** - Deadline for results submission.

- **August 8th** - Deadline for technical report submission.

- **November 10th** - Workshop date.

## Guidelines for Submissions

Participants are invited to submit their solutions for either of the two tracks through the [MIB Leaderboard](https://huggingface.co/spaces/mib-bench/leaderboard). Submissions should include the items specified in the sections below.

### Circuit Localization
<br/>
For the **Circuit Localization Track**, we expect one folder per task/model, where each folder is named after the model and the task, separated by an underscore—for example, `ioi_gpt2`, or `arc-easy_llama3`.
- You may provide either (1) one .json or .pt per folder with floating-point importance scores assigned to each node or edge in the model; or, (2) nine .json or .pt files per folder, with binary membership variables assigned to each node or edge in the model.
- If (2), there should be one circuit containing no more than each of the following percentages of edges: `{0.1, 0.2, 0.5, 1, 2, 5, 10, 20, 50}`. In other words, we expect one circuit with k ≤ 0.1 % of edges, one with k ≤ 0.2 % of edges, etc., where k is the percentage of edges in the circuit compared to the full model.
- If the code provided in the [MIB Circuit Localization Repository](https://github.com/hannamw/MIB-circuit-track) is used, the directory structure will already match the requirements.
- See [here](https://huggingface.co/mib-bench/mib-circuits-example/tree/main/importances/pt) for an example of submission type 1, and [here](https://huggingface.co/mib-bench/mib-circuits-example/tree/main/multiple_circuits/pt) for an example of submission type 2. NOTE: You are allowed to submit for a subset of models/tasks! **As long as you include ≥ 2 models and ≥ tasks, we will accept your submission.**

### Causal Variable Localization
<br/>
For the **Causal Variable Localization Track**, we expect a .py script defining an invertible featurizer, a .py script defining at which token positions the featurizer should be applied, and a folder containing a trained featurizer, trained inverse featurizer, and token indices.
- To learn more about the format of the submission, please see both the [MIB Causal Variable Localization Repository](https://github.com/atticusg/CausalAbstraction/tree/main) and [this example submission](https://huggingface.co/mib-bench/mib-causalvariable-example/tree/main).
- NOTE: the featurizer should extend the `Featurizer` class, and the modules should extend `torch.nn.Module` (or one of the existing module classes). The repository should contain a README with instructions on how to run the code, including any dependencies and installation steps.
- No minimal subset of models or tasks is required for the Causal Variable Localization track.

### Inclusion in the Final Ranking
<br/>
In order to be considered for the final ranking, submissions to either one of the tracks **must include at least the following three model/task combinations**:
<br/>
- GPT-2 on IOI
- Qwen-2.5 on IOI
- Qwen-2.5 on MCQA
<br/>
This ensures that all submissions are evaluated on a common set of tasks and models, which are selected to require as little computational resources as possible. **Submissions that do not include these three combinations will not be considered for the final ranking, but will still be included in the leaderboard.**
<br/>
Submissions to either track will be evaluated by organizers on the private test set from the MIB benchmark, and results will be made available on the [MIB Leaderboard](https://huggingface.co/spaces/mib-bench/leaderboard). Participants will be invited to submit a technical report describing their approach, results, and any insights gained during the process. The report should be no more than 4 pages long (excluding references) and follow the [BlackboxNLP 2025 formatting guidelines](https://blackboxnlp.github.io/2025/call).

## Task Details

MIB contains two tracks. The circuit localization track benchmarks methods that aim to locate graphs of causal dependencies in neural networks. The causal variable localization track benchmarks methods that aim to locate specific human-interpretable causal variables in neural networks.

### **Circuit Localization Track**

<br/>

![Circuit localization track](https://github.com/aaronmueller/MIB/blob/main/assets/circuit_track.png?raw=true)
<br/>
This track benchmarks circuit discovery methods—i.e., methods for locating graphs of causal dependencies in neural networks. Most circuit discovery pipelines look something like this:
<br/>
- Compute importance scores for each component or each edge between components.
- Ablate all components from the network except those that surpass some importance threshold, or those in the top k%.
- Evaluate how well the circuit (model with only the most important components not ablated) performs, or replicates the full model's behavior.
<br/>
In the circuit localization track, participants are asked (but not required) to employ the [MIB benchmark's provided code](https://github.com/hannamw/MIB-circuit-track) to discover and evaluate LM circuits.
<br/>
Two evaluation criteria are employed: **1. how well the circuit performs** overall (the *CPR* metric), and **2. how well it replicates the model's behavior** (the *CMD* metric). Past evaluations often implicitly conflate these two, while here we follow the MIB's approach in treating them as complementary but separate metrics. More details concerning the evaluation are available in the [MIB Circuit Localization Repository](https://github.com/hannamw/MIB-circuit-track).

### **Causal Variable Localization Track**
<br/>
![Causal variable localization track](https://github.com/aaronmueller/MIB/blob/main/assets/causal_variable_track.png?raw=true)
<br/>
This track benchmarks featurization methods—i.e., methods for transforming model activations into a space where it's easier to isolate a given causal variable. Most pipelines under this paradigm look like this:
<br/>
- Curate a dataset of contrastive pairs, where each pair differs only with respect to the targeted causal variable.
- If using a supervised method, train the featurization method using the contrastive pairs.
- To evaluate: feed the model an input from a pair, use the featurizer to transform an activation vector, intervene in the transformed space, transform back out, and see whether the model's new behavior aligns with what is expected under the intervention.
<br/>
In the causal variable localization track, participants are asked (but not required) to employ the [MIB benchmark's provided code](https://github.com/atticusg/CausalAbstraction) to train and evaluate featurizers.

## Leaderboard

The leaderboard is public! See [here](https://huggingface.co/spaces/mib-bench/leaderboard). You may submit up to **two submissions per week** (excluding those that do not pass our formatting checks). Use the public validation and test sets to prototype your methods before you submit to the leaderboard.